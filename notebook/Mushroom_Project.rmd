---
title: 'Can I eat that mushroom?'
author: "Yashdhar Gandhi "
date: "2024-05-29"
output :
  html_document:
    toc: true
    toc_float: true
    number_sections: true
bibliography: bibassignment3.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#Introduction
The "mushroom dataset" is a well-known dataset that is frequently used in machine learning research to evaluate new approaches. Its source is The Audubon Society Field Guide to North American Mushrooms (1981) [@lincoff1981national], which includes observations on mushrooms' size, colour, and odour, among other qualities. Based on these features, the main objective is to determine if a mushroom is poisonous or edible.

In this study, we will look at how decision trees and random forests can be used to predict mushroom edibility. Random forests are more complex yet may be able to provide higher prediction performance than decision trees, which are straightforward and easy to understand models. Our main goal will be to optimise each technique for maximum predictive performance. The highest performing model will be identified through cross-validation. Finally, we will apply an appropriate statistical test to determine the significance of the performance difference between the methods.


#Data Description
The attributes in the dataset are as follows:

Edible: Indicating whether the mushroom is edible or poisonous.
CapShape: The shape of the mushroom cap.
CapSurface: The surface texture of the mushroom cap.
CapColor: The color of the mushroom cap.
Odor: The odor of the mushroom.
Height: Height of the mushroom.

```{r Data Description and preprocesing, echo=FALSE}
# Load necessary libraries
library(tidyverse)
library(ggplot2)

# Load the dataset
mushrooms <- read.csv("mushrooms.csv")

# Display the structure of the dataset
str(mushrooms)

# Check for missing values
missing_values <- colSums(is.na(mushrooms))
print(missing_values)


summary(mushrooms)

# Calculate counts of edible and poisonous mushrooms
edible_count <- sum(mushrooms$Edible == "Edible")
poisonous_count <- sum(mushrooms$Edible == "Poisonous")
total_count <- nrow(mushrooms)
custom_colors <- c("cornflowerblue", "grey") 
# Create a pie chart with customizations
pie_plot <-ggplot(mushrooms, aes(x = "", fill = Edible)) +
  geom_bar(width = 1, color = "black", size = 1) +
  coord_polar(theta = "y") +
  labs(title = "Edible vs Poisonous Mushrooms",
       fill = "Edibility") +
  scale_fill_manual(values = custom_colors) + 
  theme_void() +
  theme(legend.position = "bottom")

pie_plot +
  annotate("text", x = 0, y = 0, label = paste("Edible:", edible_count), 
           size = 4, color = "black", hjust = 1.6) +
  annotate("text", x = 0, y = -0.1, label = paste("Poisonous:", poisonous_count), 
           size = 4, color = "black", hjust = -0.65) +
  annotate("text", x = 0, y = -0.2, label = paste("Total:", total_count), 
           size = 4, color = "black", hjust = 0.5)


```
The pie chart has been modified for improved readability and presentation. The colours "cornflowerblue" and "grey" distinguish between edible or poisonous mushrooms, respectively. Additionally, written comments within the chart provide the exact counts of edible, poisonous and total mushrooms, allowing for a quick and clear understanding of the data .    


#Task 1: Decision Trees and Random Forests

##Decision Trees 

A decision tree is a classifier expressed as a recursive partition of the instance space. The decision tree consists of nodes that form a rooted tree,
meaning it is a directed tree with a node called "root" that has no incoming
edges. All other nodes have exactly one incoming edge. A node with outgoing
edges is called an internal or test node. All other nodes are called leaves (also
known as terminal or decision nodes). In a decision tree, each internal node
splits the instance space into two or more sub-spaces according to a certain
discrete function of the input attributes values.[@rokach2006decision]

**Model Tuning**
The **'train'** function from the caret package is used to tune the decision tree model.

The **'trControl'** argument specifies that 20-fold cross-validation is used to assess the model's performance.

The **'tuneLength'** argument defines the number of different complexity parameter (cp) values to try.


**Model Performance**

The final decision tree is constructed using the rpart() function from the rpart package after the model has been tuned. In order to manage the tree's complexity and avoid overfitting, the optimal value for the complexity parameter (cp) is determined during the tuning phase.
The rpart.plot() function is used to visualise the final decision tree model, which includes a visual representation of the tree structure and decision rules.
To evaluate the model's performance, the predict() method is used to make predictions on the mushrooms dataset. The prediction and true labels (found in the edible column) of the dataset are compared to determine the decision tree model's accuracy. The decision tree model accurately classified 8064 of the dataset's total cases.

```{r Decision Tree, echo=FALSE}
# Load necessary libraries
library(caret)
library(rpart)
library(rpart.plot)

# Tune decision tree model for maximal predictive performance
set.seed(123)
dt_model <- train(Edible ~ ., 
                  data = mushrooms, 
                  method = "rpart", 
                  trControl = trainControl(method = "cv", number = 20),
                  tuneLength = 20)  # Tune parameters for maximal predictive performance

# Train decision tree model using the best tuned parameters
final_dt_model <- rpart(Edible ~ ., 
                        data = mushrooms, 
                        method = "class", 
                        control = rpart.control(cp = dt_model$bestTune[["cp"]]))  # Use the best tuning parameter

# Visualize the final decision tree
# Visualize the decision tree with explanation
rpart.plot(final_dt_model, type = 2, fallen.leaves = TRUE, extra = 101)


# Assess model performance
dt_predictions <- predict(final_dt_model, mushrooms, type = "class")
dt_correctly_classified <- sum(dt_predictions == mushrooms$Edible)

# Print accuracy
print(paste("Decision Tree Accuracy:", dt_correctly_classified))

```

##Random Forests
Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest.[@breiman2001random]
During training, it generates a large number of decision trees and outputs their mode (classification) or mean prediction (regression). In order to include unpredictability into the tree-building process, Random Forest uses bootstrap sampling to generate distinct training datasets for every tree.
At each tree split, a randomly selected collection of characteristics is chosen.

**Model Tuning**
Using the mushrooms dataset, the random forest model was adjusted using the train() method from the caret package. The random forest was built using the rf method, and the hyperparameters were tuned using 10-fold cross-validation (cv). The number of trees (ntree:  the best tuned number of trees) and the number of features to consider at each split (mtry: the best tuned number of features to consider) were the two hyperparameter combinations that the algorithm could investigate ten times, thanks to the tuneLength parameter being set to 10.

**Model Performance:**
The randomForest() method from the randomForest package was used to build the final random forest model after the model was tuned. The final model was built using the optimal values for the number of features (mtry) and the number of trees (ntree) found during the tuning phase.
The predict() function was used to create predictions on the mushrooms dataset in order to evaluate the model's performance. The predicted labels and the genuine labels (found in the edible column of the dataset) were compared to determine the random forest model's accuracy. With an accuracy of 0.993722304283604 , the random forest model successfully classified 8073 of the dataset's total occurrences.

**Feature Importance:**
Additionally, the random forest model sheds light on the relative significance of every feature in the prediction process.
Based on the random forest model's feature importance plot, we can conclude the following:


The most significant feature for determining whether a mushroom is edible is its odour. This feature has the biggest mean decrease in Gini impurity, indicating that it plays an important role in the random forest model's decision-making process.
The CapColor, or the colour of the mushroom cap, is the second most significant attribute. This characteristic is also very important in deciding how edible the mushroom is.
The next two significant characteristics are CapSurface and CapShape , in that order.
The Height characteristic appears to be the least important of the features evaluated in the model, implying that it makes no substantial contribution to predicting mushroom edibility.

```{r random forest, echo=FALSE}
# Load necessary library
library(randomForest)

# Convert Edible to factor
mushrooms$Edible <- as.factor(mushrooms$Edible)

# Tune the model using cross-validation
set.seed(123)
rf_model <- train(Edible ~ ., 
                  data = mushrooms, 
                  method = "rf", 
                  trControl = trainControl(method = "cv", number = 10),
                  tuneLength = 10)  # Tune parameters for maximal predictive performance

final_rf_model <- randomForest(Edible ~ ., 
                               data = mushrooms, 
                               ntree = 500,  # Use the best tuned number of trees
                               mtry =5)  # Use the best tuned number of features to consider
# Predictions
rf_predictions <- predict(final_rf_model, mushrooms)

# Calculate accuracy
rf_accuracy <- mean(rf_predictions == mushrooms$Edible)
rf_correct_predictions <- sum(rf_predictions == mushrooms$Edible)

# Print accuracy and number of correct predictions
print(paste("Random Forest Accuracy:", rf_accuracy))
print(paste("Number of Correct Predictions:", rf_correct_predictions))

# Calculate feature importance
feature_importance <- importance(final_rf_model)

# Plot feature importance
varImpPlot(final_rf_model)


```
#Task 2: Model Selection Using Cross-Validation
Cross-validation is a data resampling method to assess the generalization ability of predictive models andto prevent overﬁtting. [@hastie2008elements]

Cross-validation is the process of splitting a dataset into numerous subsets, or folds. Each fold serves as a validation set, and training is done on the remaining folds. To produce a more accurate estimate of the model's performance, this process is done several times, and performance measures are averaged over all folds. Cross-validation reduces the chance of overfitting and aids in assessing a model's capacity for generalisation.


```{r Cross Validation, echo= FALSE}
# Load necessary libraries
library(caret)
library(rpart)
library(randomForest)

# Define the number of folds for cross-validation
num_folds <- 10  # Example: 10-fold cross-validation

# Define a function to perform cross-validation for a given model
perform_cross_validation <- function(model, data, num_folds) {
  # Create a list to store performance metrics for each fold
  performance_metrics <- list()
  
  # Perform k-fold cross-validation
  folds <- createFolds(data$Edible, k = num_folds, list = TRUE)
  for (i in 1:num_folds) {
    # Split data into training and validation sets
    train_indices <- unlist(folds[-i])
    validation_indices <- unlist(folds[i])
    train_data <- data[train_indices, ]
    validation_data <- data[validation_indices, ]
    
    # Train the model on the training data
    model_fit <- train(Edible ~ ., data = train_data, method = model)
    
    # Make predictions on the validation data
    predictions <- predict(model_fit, newdata = validation_data)
    
    # Calculate performance metrics
    accuracy <- sum(predictions == validation_data$Edible) / length(predictions)
    confusion_matrix <- confusionMatrix(predictions, validation_data$Edible)
    precision <- confusion_matrix$byClass["Precision"]
    recall <- confusion_matrix$byClass["Recall"]
    f1_score <- confusion_matrix$byClass["F1"]
    
    # Store performance metrics for this fold
    performance_metrics[[i]] <- c(accuracy, precision, recall, f1_score)
  }
  
  return(do.call(rbind, performance_metrics))
}

# Perform cross-validation for decision tree model
dt_performance <- perform_cross_validation("rpart", mushrooms, num_folds)

# Perform cross-validation for random forest model
rf_performance <- perform_cross_validation("rf", mushrooms, num_folds)

# Print all the values necessary for calculating Performance Metrics
print("Decision Tree Performance Metrics:")
print(dt_performance)
print("Random Forest Performance Metrics:")
print(rf_performance)

# Calculate mean performance metrics for decision tree
dt_mean_performance <- colMeans(dt_performance)
print("Mean Performance Metrics for Decision Tree:")
print(dt_mean_performance)

# Calculate mean performance metrics for random forest
rf_mean_performance <- colMeans(rf_performance)
print("Mean Performance Metrics for Random Forest:")
print(rf_mean_performance)

# Perform paired t-test on Accuracy
t_test_accuracy <- t.test(dt_performance[, 1], rf_performance[, 1], paired = TRUE)
print("Paired t-test Results for Accuracy:")
print(t_test_accuracy)

# Perform paired t-test on Precision
t_test_precision <- t.test(dt_performance[, 2], rf_performance[, 2], paired = TRUE)
print("Paired t-test Results for Precision:")
print(t_test_precision)

# Perform paired t-test on Recall
t_test_recall <- t.test(dt_performance[, 3], rf_performance[, 3], paired = TRUE)
print("Paired t-test Results for Recall:")
print(t_test_recall)

# Perform paired t-test on F1 Score
t_test_f1 <- t.test(dt_performance[, 4], rf_performance[, 4], paired = TRUE)
print("Paired t-test Results for F1 Score:")
print(t_test_f1)

```
**Cross-Validation Performance Metrics**

**Decision Tree Performance Metrics:**
Accuracy: Average accuracy across folds is approximately 93.60%.
Precision: Average precision across folds is approximately 96.95%.
Recall: Average recall across folds is approximately 90.49%.
F1 Score: Average F1 score across folds is approximately 93.60%.

**Random Forest Performance Metrics:**
Accuracy: Average accuracy across folds is approximately 99.18%.
Precision: Average precision across folds is approximately 99.89%.
Recall: Average recall across folds is approximately 99.52%.
F1 Score: Average F1 score across folds is approximately 99.21%.

**Interpretation:**
In comparison to the decision tree model, the random forest model exhibits greater average accuracy, precision, recall, and F1 score. This indicates that the random forest model greatly outperforms the other models in accurately categorising the mushrooms.

**Paired t-test Results:**

Accuracy:
t = -12.054, df = 9, p-value = 7.409e-07
The p-value is extremely small, indicating a significant difference in accuracy between the decision tree and random forest models.
The mean difference in accuracy indicates that the random forest model has significantly higher accuracy than the decision tree model.
Precision:
t = -4.4241, df = 9, p-value = 0.001661
The p-value is very small, indicating a significant difference in precision between the models.
The mean difference in precision indicates that the random forest model has significantly higher precision than the decision tree model.
Recall:
t = -13.487, df = 9, p-value = 2.83e-07
The p-value is extremely small, indicating a significant difference in recall between the models.
The mean difference in recall indicates that the random forest model has significantly higher recall than the decision tree model.
F1 Score:
t = -11.917, df = 9, p-value = 8.167e-07
The p-value is extremely small, indicating a significant difference in F1 score between the models.
The mean difference in F1 score indicates that the random forest model has significantly higher F1 score than the decision tree model.

With p-values less than 0.05 for accuracy, precision, recall, and F1 score, the paired t-test findings show that the random forest model performed significantly better than the decision tree model across all performance parameters.

Determining if the observed differences in performance indicators (such as accuracy, precision, recall, and F1 score) are statistically significant is critical when evaluating the performance of two models. We utilise the paired t-test to do this.



#Conclusion

**Summary of Findings:**
We looked into the use of random forests and decision trees for predicting the edibility of mushrooms depending on a variety of attributes, including height, odour, colour, surface, and form of the cap. We observed that the random forest model outperformed the decision tree model in terms of accuracy, precision, recall, and F1 score.

**Best Model for Predicting Mushroom Edibility:**
The best model for estimating the edibility of mushrooms turned out to be the random forest model. All performance indicators, including accuracy (0.9917521), precision (0.98889180), recall (0.9952449), and F1 score (0.99920639), were higher on average. The statistical significance of the performance differences between the random forest and decision tree models was further validated by the paired t-test results.

**Significance of the Results and Implications :**
Predicting a mushroom's edibility with precision is essential to avoid potentially lethal cases of mushroom poisoning. With respect to differentiating between edible and poisonous mushrooms, the random forest model performs excellently, as seen by its high performance metrics. These findings provide a reliable approach for detecting safe and edible mushrooms, which has important ramifications for food industry professionals, and gourmet fans.


**Potential Improvements:**
There are various possible modifications that could be investigated:

Feature Engineering: Investigating additional relevant features or deriving new features from the existing ones could potentially enhance the model's predictive power.
Ensemble Methods: To get even greater performance gains, the random forest model can be combined with additional ensemble techniques like gradient boosting or stacking.
Transfer Learning: By utilising pre-trained models on relevant datasets, transfer learning techniques may be investigated with the aim of enhancing model performance, particularly in situations where data is limited.
Interpretability: Although random forests offer feature importance scores, a variety of strategies could enhance the model's predictions' interpretability, facilitating a deeper comprehension of the decision-making process.


#References
Lincoff, G., & National Audubon Society. (1981). National Audubon Society Field
Guide to North American Mushrooms. A Chanticleer Press Edition. Knopf
Doubleday Publishing Group. ISBN: 9780394519920.
https://bookas.google.co.uk/books?id=bf8UAQAAIAAJ

Rokach, L., & Maimon, O. (2006). Decision Trees. In Springer eBooks (pp. 165–
192). Springer. DOI: 10.1007/0-387-25465-x_9

Breiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32. DOI:
10.1023/A:1010933404324

Hastie, T., Tibshirani, R., & Friedman, J. (2008). The Elements of Statistical
Learning (2nd ed.). Springer. New York/Berlin/Heidelberg.
